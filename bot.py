import json
import os
from difflib import SequenceMatcher
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from dotenv import load_dotenv

from vercel_storage import vercel_storage
from flan_service import flan_service, DEFAULT_CONTEXT
from ppc_search import ppc_search

load_dotenv()

TOKEN = os.getenv("TELEGRAM_TOKEN")

# Carrega perguntas e respostas
with open("public/perguntas_respostas_melhorado.json", encoding="utf-8") as f:
    QA = json.load(f)

# Menus
MAIN_MENU = [
    ["ðŸ“š InformaÃ§Ãµes sobre EstÃ¡gio"],
    ["ðŸŽ“ InformaÃ§Ãµes sobre MatrÃ­cula"],    
    ["ðŸ“ Registrar Dados AcadÃªmicos"],
]

ESTAGIO_MENU = [
    ["ðŸ“‹ Requisitos para EstÃ¡gio"],
    ["ðŸ“„ Documentos NecessÃ¡rios"],
    ["â° Prazos e Cronograma"],
    ["ðŸ¢ Como Encontrar Empresas"],
    ["ðŸ”™ Voltar ao Menu Principal"]
]

MATRICULA_MENU = [
    ["ðŸ“… CalendÃ¡rio AcadÃªmico"],
    ["ðŸ“ Como se Matricular"],
    ["ðŸ”„ Trancamento/Cancelamento"],
    ["ðŸ“Š HistÃ³rico Escolar"],
    ["ðŸ”™ Voltar ao Menu Principal"]
]

# FunÃ§Ã£o de similaridade melhorada
def similarity(a: str, b: str) -> float:
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()

def advanced_similarity(query: str, item: dict) -> float:
    """Calcula similaridade avanÃ§ada considerando mÃºltiplos fatores"""
    query_lower = query.lower()
    
    # Similaridade com a pergunta principal
    main_score = similarity(query, item["pergunta"])
    
    # Similaridade com variaÃ§Ãµes
    variation_scores = []
    for variacao in item.get("variacoes", []):
        variation_scores.append(similarity(query, variacao))
    
    max_variation_score = max(variation_scores) if variation_scores else 0
    
    # Similaridade com tags
    tag_score = 0
    for tag in item.get("tags", []):
        if tag.lower() in query_lower:
            tag_score += 0.3
    
    # PontuaÃ§Ã£o por palavras-chave especÃ­ficas
    keyword_score = 0
    query_words = query_lower.split()
    for word in query_words:
        if len(word) > 3:  # Ignora palavras muito pequenas
            for variacao in item.get("variacoes", []):
                if word in variacao.lower():
                    keyword_score += 0.2
    
    # Combina as pontuaÃ§Ãµes
    final_score = max(main_score, max_variation_score) * 0.6 + tag_score * 0.2 + keyword_score * 0.2
    
    return min(final_score, 1.0)  # Limita a 1.0

# ðŸ Start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await vercel_storage.store_analytics("bot_start", {
        "user_id": update.effective_user.id,
        "username": update.effective_user.username,
        "first_name": update.effective_user.first_name
    })

    await update.message.reply_text(
        f"ðŸŽ“ OlÃ¡ {update.effective_user.first_name}! Bem-vindo ao ChatBot da CoordenaÃ§Ã£o de Engenharia de Software.\n\n"
        "Escolha uma opÃ§Ã£o abaixo ou digite sua pergunta.",
        reply_markup=ReplyKeyboardMarkup(MAIN_MENU, resize_keyboard=True)
    )
    context.user_data["step"] = "main_menu"

# ðŸŽ¯ Menu Principal
async def handle_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.message.text

    if msg == "ðŸ“š InformaÃ§Ãµes sobre EstÃ¡gio":
        await update.message.reply_text(
            "Selecione uma opÃ§Ã£o:",
            reply_markup=ReplyKeyboardMarkup(ESTAGIO_MENU, resize_keyboard=True)
        )
        context.user_data["step"] = "estagio_menu"

    elif msg == "ðŸŽ“ InformaÃ§Ãµes sobre MatrÃ­cula":
        await update.message.reply_text(
            "Selecione uma opÃ§Ã£o:",
            reply_markup=ReplyKeyboardMarkup(MATRICULA_MENU, resize_keyboard=True)
        )
        context.user_data["step"] = "matricula_menu"

    elif msg == "ðŸ“ Registrar Dados AcadÃªmicos":
        context.user_data["step"] = "cadastro_nome"
        await update.message.reply_text("Informe seu nome completo:", reply_markup=ReplyKeyboardRemove())

    elif msg == "ðŸ”™ Voltar ao Menu Principal":
        await start(update, context)

    else:
        await handle_free_question(update, context)

# ðŸ“ Cadastro guiado
async def handle_cadastro(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_data = await vercel_storage.get_user_data(user.id) or {}

    text = (
        "ðŸ“ **Seus Dados AcadÃªmicos**\n\n"
        f"ðŸ‘¤ Nome: {user_data.get('nome', 'NÃ£o informado')}\n"
        f"ðŸŽ“ MatrÃ­cula: {user_data.get('matricula', 'NÃ£o informado')}\n"
        f"ðŸ“… Semestre: {user_data.get('semestre', 'NÃ£o informado')}\n"
        f"ðŸ“§ Email: {user_data.get('email', 'NÃ£o informado')}\n\n"
        "Para atualizar, use os comandos:\n"
        "/nome Seu Nome\n"
        "/matricula 123456\n"
        "/semestre de inicio2024.1\n"
        "/email seu@email.com"
    )

    await update.message.reply_text(text, parse_mode="Markdown")
    
# â“ Perguntas livres
async def handle_free_question(update: Update, context: ContextTypes.DEFAULT_TYPE):
    question = update.message.text
    
    # 1. Busca avanÃ§ada no JSON local
    scored_items = []
    for item in QA:
        score = advanced_similarity(question, item)
        if score > 0.3:  # Threshold mais baixo para capturar mais opÃ§Ãµes
            scored_items.append((item, score))
    
    # Ordena por score e pega o melhor
    if scored_items:
        scored_items.sort(key=lambda x: x[1], reverse=True)
        best_match, best_score = scored_items[0]
        
        if best_score >= 0.5:  # Threshold ajustado
            response = best_match["resposta"]
            await update.message.reply_text(response, parse_mode='Markdown')
            return

    # 2. Busca por tags (mantida como fallback)
    for qa_item in QA:
        if any(tag.lower() in question.lower() for tag in qa_item.get("tags", [])):
            response = qa_item["resposta"]
            await update.message.reply_text(response, parse_mode='Markdown')
            return

    # 3. Busca no PPC
    ppc_response = ppc_search.get_formatted_response(question)
    if ppc_response:
        await update.message.reply_text(ppc_response, parse_mode='Markdown')
        return

    # 4. Fallback para FLAN com contexto do PPC
    try:
        # Contexto dinÃ¢mico baseado no PPC
        ppc_context = ppc_search.get_context_for_flan(question)
        context_text = f"{DEFAULT_CONTEXT}\n\nContexto do PPC:\n{ppc_context}"
        
        resposta = flan_service.generate_response(question, context_text)
        await update.message.reply_text(resposta, parse_mode='Markdown')
    except Exception as e:
        print(f"Erro FLAN-T5: {e}")
        await update.message.reply_text(
            "ðŸ˜” NÃ£o consegui encontrar uma resposta precisa para sua pergunta.\n\n"
            "ðŸ’¡ **SugestÃµes:**\n"
            "â€¢ Tente reformular sua pergunta\n"
            "â€¢ Use palavras-chave mais especÃ­ficas\n"
            "â€¢ Consulte: https://es.quixada.ufc.br\n"
            "â€¢ Fale com a coordenaÃ§Ã£o: es@quixada.ufc.br",
            parse_mode='Markdown'
        )
# ðŸš€ Main
def main():
    print("ðŸ¤– Bot iniciado...")
    app = Application.builder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, route_message))

    print("âœ… Bot rodando!")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

# ðŸ”€ Roteador
async def route_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    step = context.user_data.get("step", "main_menu")
    if step.startswith("cadastro"):
        await handle_cadastro(update, context)
    else:
        await handle_menu(update, context)

if __name__ == "__main__":
    main()
